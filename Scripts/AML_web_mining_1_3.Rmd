---
title: "AML Web Mining(Data preparation)"
author: "Felipe Jiménez"
date: "Wednesday, May 20, 2015"
output:
  html_document:
    highlight: textmate
    theme: spacelab
    toc: yes
---
#Task Nº1.3:Generar data para modelos de entrenamiento
*Transformación  de los documentos en objetos analizables para generar los modelos de entrenamiento.*


```{r CONFIGURATION,message=FALSE,warning=FALSE}

#Lista de paquetes a utilizar

paquetes <- c("tm","tm.plugin.webmining","RTextTools","topicmodels",
              "RWeka","wordcloud","dplyr","data.table","rgdal","stringr","stargazer")

#Verifica si los paquetes a utilizar están instalados, caso contrario los instala

for (i in paquetes){
  if (i %in% installed.packages()[,"Package"] == FALSE){
    install.packages(i);
  }
}

#Carga de paquetes

invisible(sapply(paquetes,library,character.only=TRUE))

```

##Parámetros
```{r PARAMETERS}

#Directorios

pathin<- c("C:/Users/Felipe/Dropbox/Didactico/Universidad/Maestria_Estadistica/Practica_Profesional/AML_web_mining/Datos")

pathou<- c("C:/Users/Felipe/Dropbox/Didactico/Universidad/Maestria_Estadistica/Practica_Profesional/AML_web_mining/Objetos")

setwd(pathin)

#Palabras clave para buscar textos relacionados al LA/FT

#Español
AMLKEYSsp<- as.vector(as.matrix(read.csv("amlkeyssp.csv",header = FALSE,sep=";"))[,1])
#Inglés
AMLKEYSen<- as.vector(as.matrix(read.csv("amlkeysen.csv",header = FALSE,sep=";"))[,1])

AMLKEYS<-c(AMLKEYSsp,AMLKEYSen)

head(AMLKEYS)


#Descarga de información de países para análisis geográfico

download.file(file.path('http://www.naturalearthdata.com/http/',
                        'www.naturalearthdata.com/download/50m/cultural',
                        'ne_50m_admin_0_countries.zip'),
              f <- tempfile())

unzip(f, exdir=tempdir())

world <- readOGR(tempdir(), 'ne_50m_admin_0_countries', encoding='UTF-8')

paises<-data.frame(pais=world$admin,
                   count=rep(0,length(world$admin)),
                   subregion=world$subregion,
                   region=world$region_wb,
                   continent=world$region_un,
                   stringsAsFactors=FALSE)

paises<-paises %>%
  filter(subregion=="Central America")


```

##Preparación de data

*Función para n-grams, Tomada de:* 

[BigramTokenizer](http://stackoverflow.com/questions/8898521/finding-2-3-word-phrases-using-r-tm-package)

```{r TEXT MINING PREPARATION,,warning=FALSE}

#Carga de objetos creados
load(paste0(pathou,"/","2_corpusclean.RData"))
load(paste0(pathou,"/","2_corpuscleanstem.RData"))

load(paste0(pathou,"/","1_corpusen.RData"))
load(paste0(pathou,"/","1_corpussp.RData"))

#Unir los corpus en ambos idiomas

corpusraw<-c(Tsp,Ten,recursive = TRUE)

#-----------------Obtener la cantidad de noticias por día por país------------------------

paisesfechas<-list()

for(i in 1:nrow(paises)){
  
  paisesfechas[[i]]<-tm_filter(corpusraw,FUN = function(x) any(agrep(paises[i,1],
                                                                content(x))))
  
  paisesfechas[[i]]<-data.frame(pais=paises[i,1],
                     fecha=sapply(meta(paisesfechas[[i]],"datetimestamp"),substr,1,10),
                     stringsAsFactors=FALSE )
  }

#Generando un solo Dataframe de las listas
paisesfechas<- rbindlist(paisesfechas)

#-----------------------Generación de DTMs según N-grams-------------------------

BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 2))

#Control

#control<- list(dictionary =AMLKEYS,global = c(5, Inf),wordLengths=c(4,Inf),
#weighting=weightTf,tokenize=BigramTokenizer)

control1<- list(global = c(5, Inf),wordLengths=c(4,Inf),
               weighting=weightTf)

control2<- list(global = c(5, Inf),wordLengths=c(4,Inf),
               weighting=weightTf,tokenize = BigramTokenizer)

#Objetos DTM/TDM
dtm1g <- DocumentTermMatrix(corpuscleanstem,control=control1)
dtm2g <- DocumentTermMatrix(corpuscleanstem,control=control2)

<<<<<<< HEAD
#versión sin stemming(para análisis exploratorio y relaciones de tokens)
dtm2gb <- DocumentTermMatrix(corpusclean,control=control2) 
tdm2gb <- TermDocumentMatrix(corpusclean,control=control2) 

#Generar versiones con W= Tf-Idf
dtm2gTfIdf <- weightTfIdf(dtm2g, normalize = TRUE)

dtm2gbTfIdf <- weightTfIdf(DocumentTermMatrix(corpusclean,control=control2),normalize = TRUE) 
tdm2gbTfIdf <- weightTfIdf(TermDocumentMatrix(corpusclean,control=control2), normalize = TRUE)

#Remover términos poco frecuentes
dtm1g90 <- removeSparseTerms(dtm1g,sparse=.9);dtm1g90
dtm2g90 <- removeSparseTerms(dtm2g,sparse=.9);dtm2g90
dtm2g98 <- removeSparseTerms(dtm2g,sparse=.98);dtm2g98

#DTM 2-grams con TF-IDF Weight
dtm2gTfIdf98 <- removeSparseTerms(dtm2gTfIdf,sparse=.98);dtm2gTfIdf98 

#dtmterms<-inspect(dtm1g90[1:dtm1g90$nrow, 1:dtm1g90$ncol])
=======
dtm2gTfIdf <- weightTfIdf(dtm2g, normalize = TRUE)


#Remover términos poco frecuentes
dtm1g90 <- removeSparseTerms(dtm1g,sparse=.9)
dtm2g98 <- removeSparseTerms(dtm2g,sparse=.98)

#DTM 2-grams con TF-IDF Weight
dtm2gTfIdf98 <- removeSparseTerms(dtm2gTfIdf,sparse=.98)

#dtmterms<-inspect(dtm1g90[1:dtm1g90$nrow, 1:dtm1g90$ncol])



```

##Exploración de data
```{r TEXT ANALYTICS, fig.align='center',dev="png",dev.args=list(type="cairo"),dpi=96,fig.align='center',fig.height=10,fig.width=15,warning=FALSE}

#Se obtienen términos más frecuentes para eliminar términos no relativos al tema.
findFreqTerms(dtm1g90,20)
findFreqTerms(dtm2gTfIdf98,2)

#Generar Word Cloud para visualizar términos más frecuentes

tdm <- removeSparseTerms(
  weightTfIdf(
    TermDocumentMatrix(corpus),
    normalize = TRUE),
  sparse=.98)

	m <- as.matrix(tdm)
	v <- sort(rowSums(m),decreasing=TRUE)
	d <- data.frame(word = names(v),freq=v)
	
	wordcloud(d$word,d$freq,scale=c(5,0.1),min.freq=30, max.words=300,
          random.order=FALSE, rot.per=0.35,use.r.layout=FALSE,
          colors=brewer.pal(8,"Dark2"))

#Buscar asociaciones entre términos del diccionario y del DTM
findAssocs(dtm2gTfIdf98,AMLKEYS,0.4)
>>>>>>> a0b93350cefaf42e6adf0fba2fedfbc0e2a19722

#Transformar el dtm para que pueda ser leído por el modelo de tópicos
#Se eliminan los docs que no tienen frecuencia asociada a ningún tema.
rowTotals <- apply(dtm2gTfIdf98,1, sum)
dtmf <- dtm2gTfIdf98[rowTotals>0,]

#Comparar los dtms(con documentos sin ceros y con ceros)
dim(dtm2gTfIdf98)
dim(dtmf)

#Generar tdm para wordcloud y exploración de relación de tokens

tdm99 <- removeSparseTerms(
  weightTfIdf(
    TermDocumentMatrix(corpusclean,control=control2),
    normalize = TRUE),
  sparse=.99)

#Guardar  objetos final

#DTM para modelos de clasificación
save(dtmf,file = paste0(pathou,"/","3_dtmAML.RData"))

#TDM/DTM/DF para exploración
save(tdm99,file = paste0(pathou,"/","3_tdmAML.RData"))
save(tdm2gbTfIdf,file = paste0(pathou,"/","3_tdm2AML.RData"))

save(dtm1g90,file = paste0(pathou,"/","3_dtm2AML.RData"))
save(dtm2g90,file = paste0(pathou,"/","3_dtm3AML.RData"))
save(dtm2g98,file = paste0(pathou,"/","3_dtm4AML.RData"))
save(dtm2gTfIdf98,file = paste0(pathou,"/","3_dtm5AML.RData"))
save(dtm2gbTfIdf,file = paste0(pathou,"/","3_dtm6AML.RData"))

save(paisesfechas,file = paste0(pathou,"/","paisesfechasAML.RData"))
save(world,file = paste0(pathou,"/","worldAML.RData"))

```

